{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e60da194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import nltk\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd7c50e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\distributions\\distribution.py:259: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\distributions\\bernoulli.py:165: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "251661cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"QCC4AQUW1ZKX4T7P\"\n",
    "symbol = \"TCS.BSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b5f6e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol}&outputsize=full&apikey={API_KEY}&datatype=csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77478163",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ec220fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to tcs_stock_data.csv\n"
     ]
    }
   ],
   "source": [
    "# print response\n",
    "if response.status_code == 200:\n",
    "    with open('tcs_stock_data.csv', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(\"Data saved to tcs_stock_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee520c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the data in a pandas dataframe\n",
    "df = pd.read_csv('tcs_stock_data.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6ae2836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 open       high        low      close  volume\n",
      "timestamp                                                     \n",
      "2025-06-30  3444.9500  3465.0000  3430.1499  3461.0500   80588\n",
      "2025-07-01  3460.9500  3485.0000  3414.4500  3429.4500  221565\n",
      "2025-07-02  3450.0500  3489.8501  3420.1001  3423.3501   54493\n",
      "2025-07-03  3434.8999  3435.0000  3398.1499  3400.7500  113506\n",
      "2025-07-04  3401.1001  3426.0000  3388.6499  3420.9500  170988\n"
     ]
    }
   ],
   "source": [
    "df.index = pd.to_datetime(df.index)\n",
    "df = df.sort_index()\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8079fe4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['open', 'high', 'low', 'close', 'volume', 'RSI_14', 'MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_12_26_9', 'EMA_20', 'SMA_50', 'OBV', 'BBL_5_2.0', 'BBM_5_2.0', 'BBU_5_2.0', 'BBB_5_2.0', 'BBP_5_2.0', 'CCI_14_0.015', 'ATRr_14', 'ADX', 'DI+', 'DI-', 'trend_signal', 'MA100', 'MA200', 'MA_signal']\n"
     ]
    }
   ],
   "source": [
    "# show all column names\n",
    "print(\"Column names:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b01e5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82df34e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add multiple indicators\n",
    "df.ta.rsi(append=True)                      # RSI\n",
    "df.ta.macd(append=True)                     # MACD (MACDEXT style)\n",
    "df.ta.ema(length=20, append=True)           # EMA20\n",
    "df.ta.sma(length=50, append=True)           # SMA50\n",
    "df.ta.obv(append=True)                      # On Balance Volume\n",
    "df.ta.bbands(append=True)                   # Bollinger Bands\n",
    "df.ta.cci(append=True)                      # CCI\n",
    "df.ta.atr(append=True)                      # ATR\n",
    "\n",
    "# Clean up: Drop NaN values created by indicators (lookback periods)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76422685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ADX with 14-day period (default)\n",
    "adx = ta.adx(df['high'], df['low'], df['close'])\n",
    "\n",
    "# Merge into your main DataFrame\n",
    "df = pd.concat([df, adx], axis=1)\n",
    "\n",
    "# Optional: Simplify naming\n",
    "df.rename(columns={\n",
    "    'ADX_14': 'ADX',\n",
    "    'DMP_14': 'DI+',\n",
    "    'DMN_14': 'DI-'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bb91cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend_direction(row):\n",
    "    if row['ADX'] > 25:\n",
    "        if row['DI+'] > row['DI-']:\n",
    "            return 1   # strong uptrend\n",
    "        else:\n",
    "            return -1  # strong downtrend\n",
    "    return 0  # no clear trend\n",
    "\n",
    "df['trend_signal'] = df.apply(trend_direction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9e843d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MA\n",
    "df['MA100'] = df['close'].rolling(100).mean()\n",
    "df['MA200'] = df['close'].rolling(200).mean()\n",
    "df['MA_signal'] = (df['MA100'] > df['MA200']).astype(int)\n",
    "\n",
    "# Drop NA\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7995bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ Select features\n",
    "features = ['open', 'high', 'low', 'close', 'volume',\n",
    "            'RSI_14', 'MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_12_26_9',\n",
    "            'EMA_20', 'SMA_50', 'OBV', 'BBL_5_2.0', 'BBM_5_2.0', 'BBU_5_2.0',\n",
    "            'BBB_5_2.0', 'BBP_5_2.0', 'CCI_14_0.015', 'ATRr_14',\n",
    "            'ADX', 'DI+', 'DI-', 'trend_signal', 'MA100', 'MA200', 'MA_signal']\n",
    "\n",
    "# 2️⃣ Scaling features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df[features])\n",
    "\n",
    "# 3️⃣ Create sequences\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "sequence_length = 60  # last 60 days\n",
    "target_col_index = features.index('close')  # we'll predict next 'close' price\n",
    "\n",
    "for i in range(sequence_length, len(scaled_data)):\n",
    "    X.append(scaled_data[i - sequence_length:i])\n",
    "    y.append(scaled_data[i][target_col_index])  # predicting close price\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "# 4️⃣ Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9449a3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 60, 128)           79360     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 60, 128)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 128,833\n",
      "Trainable params: 128,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=128, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=64, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))  # Predicting the closing price\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d505ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb69a369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 open       high        low      close  volume      RSI  \\\n",
      "timestamp                                                                 \n",
      "2025-07-04  3401.1001  3426.0000  3388.6499  3420.9500  170988  47.6243   \n",
      "2025-07-03  3434.8999  3435.0000  3398.1499  3400.7500  113506  44.2725   \n",
      "2025-07-02  3450.0500  3489.8501  3420.1001  3423.3501   54493  47.4255   \n",
      "2025-07-01  3460.9500  3485.0000  3414.4500  3429.4500  221565  48.2875   \n",
      "2025-06-30  3444.9500  3465.0000  3430.1499  3461.0500   80588  52.9134   \n",
      "\n",
      "                 SMA        EMA  Real Upper Band  Real Middle Band  \\\n",
      "timestamp                                                            \n",
      "2025-07-04  3434.860  3436.4619        3501.4278         3440.5700   \n",
      "2025-07-03  3437.185  3444.3201        3503.7413         3438.8075   \n",
      "2025-07-02  3438.565  3446.4134        3506.7391         3437.3675   \n",
      "2025-07-01  3445.995  3445.6053        3508.7152         3435.2275   \n",
      "2025-06-30  3450.900  3442.1954        3510.5360         3432.5075   \n",
      "\n",
      "            Real Lower Band  \n",
      "timestamp                    \n",
      "2025-07-04        3379.7122  \n",
      "2025-07-03        3373.8737  \n",
      "2025-07-02        3367.9959  \n",
      "2025-07-01        3361.7398  \n",
      "2025-06-30        3354.4790  \n"
     ]
    }
   ],
   "source": [
    "# Filter data from the last 3 years\n",
    "cutoff_date = datetime.now() - timedelta(days=3*365)\n",
    "df_recent = df[df.index >= cutoff_date]\n",
    "\n",
    "print(df_recent.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a3ca3601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_headlines(keyword=\"TCS\", num_days=30):\n",
    "    headlines = {}\n",
    "\n",
    "    for i in range(num_days):\n",
    "        date = datetime.now() - timedelta(days=i)\n",
    "        formatted_date = date.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Google News RSS (can filter date later)\n",
    "        url = f\"https://news.google.com/rss/search?q={keyword}+when:{i}d\"\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.content, features=\"html.parser\")\n",
    "        items = soup.findAll(\"item\")\n",
    "\n",
    "        headlines[formatted_date] = [item.title.text for item in items]\n",
    "\n",
    "    return headlines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c2412013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_daily_sentiment(headlines_dict):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    sentiment_scores = {}\n",
    "\n",
    "    for date, titles in headlines_dict.items():\n",
    "        scores = [analyzer.polarity_scores(title)['compound'] for title in titles]\n",
    "        avg_score = sum(scores) / len(scores) if scores else 0\n",
    "        sentiment_scores[date] = avg_score\n",
    "\n",
    "    return sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6400ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "headline_data = get_news_headlines(\"Reliance Industry\", num_days=365*3)\n",
    "sentiment_scores = compute_daily_sentiment(headline_data)\n",
    "\n",
    "sentiment_df = pd.DataFrame(list(sentiment_scores.items()), columns=['Date', 'Sentiment'])\n",
    "sentiment_df['Date'] = pd.to_datetime(sentiment_df['Date'])\n",
    "sentiment_df.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb165f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
